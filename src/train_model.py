"""
–ú–æ–¥—É–ª—å –æ–±—É—á–µ–Ω–∏—è ML-–º–æ–¥–µ–ª–∏ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Ü–µ–Ω –±–∏–¥–æ–≤ –≤–æ–¥–∏—Ç–µ–ª–µ–π Drivee
–í–∫–ª—é—á–∞–µ—Ç –æ—á–∏—Å—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö, feature engineering –∏ –æ–±—É—á–µ–Ω–∏–µ XGBoost
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.calibration import CalibratedClassifierCV
from sklearn.metrics import roc_auc_score, precision_recall_curve, auc
import xgboost as xgb
import joblib
import warnings
warnings.filterwarnings('ignore')


def clean_and_validate_data(df, verbose=True):
    """
    –û—á–∏—â–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –æ—Ç —Ñ–∏–∑–∏—á–µ—Å–∫–∏ –Ω–µ–≤–æ–∑–º–æ–∂–Ω—ã—Ö –∏ –Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
    
    Args:
        df: –ò—Å—Ö–æ–¥–Ω—ã–π DataFrame
        verbose: –í—ã–≤–æ–¥–∏—Ç—å –ª–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        
    Returns:
        pd.DataFrame: –û—á–∏—â–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
    """
    
    initial_count = len(df)
    
    if verbose:
        print("\n" + "="*70)
        print("–û–ß–ò–°–¢–ö–ê –ò –í–ê–õ–ò–î–ê–¶–ò–Ø –î–ê–ù–ù–´–•")
        print("="*70)
        print(f"–ò—Å—Ö–æ–¥–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π: {initial_count}\n")
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫
    df['order_timestamp'] = pd.to_datetime(df['order_timestamp'], errors='coerce')
    df['tender_timestamp'] = pd.to_datetime(df['tender_timestamp'], errors='coerce')
    df['driver_reg_date'] = pd.to_datetime(df['driver_reg_date'], errors='coerce')
    
    # –†–∞—Å—á—ë—Ç –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    df['response_time_seconds'] = (df['tender_timestamp'] - df['order_timestamp']).dt.total_seconds()
    df['avg_speed_kmh'] = (df['distance_in_meters'] / df['duration_in_seconds'] * 3.6)
    df['avg_speed_kmh'] = df['avg_speed_kmh'].replace([np.inf, -np.inf], np.nan)
    df['pickup_speed_kmh'] = (df['pickup_in_meters'] / df['pickup_in_seconds'] * 3.6)
    df['pickup_speed_kmh'] = df['pickup_speed_kmh'].replace([np.inf, -np.inf], np.nan)
    df['pickup_ratio'] = df['pickup_in_meters'] / df['distance_in_meters']
    df['pickup_ratio'] = df['pickup_ratio'].replace([np.inf, -np.inf], np.nan)
    df['price_increase_pct'] = ((df['price_bid_local'] - df['price_start_local']) / df['price_start_local'] * 100)
    
    # –°–æ–∑–¥–∞—ë–º –º–∞—Å–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –ø—Ä–æ–±–ª–µ–º—ã
    problems = {}
    
    # 1. –í—Ä–µ–º–µ–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏
    problems['future_driver'] = (df['driver_reg_date'] > df['order_timestamp'])
    problems['future_bid'] = (df['tender_timestamp'] < df['order_timestamp'])
    problems['slow_response'] = (df['response_time_seconds'] > 300)  # >5 –º–∏–Ω—É—Ç
    
    # 2. –ù—É–ª–µ–≤—ã–µ/–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    problems['zero_distance'] = (df['distance_in_meters'] <= 0)
    problems['zero_duration'] = (df['duration_in_seconds'] <= 0)
    problems['zero_price'] = (df['price_bid_local'] <= 0)
    
    # 3. –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    problems['extreme_distance'] = (df['distance_in_meters'] > 100000)  # >100 –∫–º
    problems['extreme_duration'] = (df['duration_in_seconds'] > 7200)   # >2 —á–∞—Å–∞
    
    # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∏–∑–∏—á–µ—Å–∫–æ–π –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–∫–æ—Ä–æ—Å—Ç–∏
    problems['too_fast_city'] = (df['avg_speed_kmh'].notna()) & (df['avg_speed_kmh'] > 80)
    min_possible_duration = df['distance_in_meters'] / (120 / 3.6)
    problems['physically_impossible'] = (df['duration_in_seconds'] < min_possible_duration)
    problems['too_slow'] = (df['avg_speed_kmh'].notna()) & (df['avg_speed_kmh'] < 8)
    
    # 5. –ê–Ω–æ–º–∞–ª–∏–∏ –≤ –ø–æ–¥–∞—á–µ
    problems['extreme_pickup_ratio'] = (df['pickup_ratio'].notna()) & (df['pickup_ratio'] > 5)
    problems['extreme_pickup_speed'] = (df['pickup_speed_kmh'].notna()) & (df['pickup_speed_kmh'] > 100)
    
    # 6. –¶–µ–Ω–æ–≤—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏
    problems['extreme_markup'] = (df['price_increase_pct'] > 100)
    problems['extreme_price'] = (df['price_bid_local'] > 5000)
    
    # –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    if verbose:
        descriptions = {
            'future_driver': '–í–æ–¥–∏—Ç–µ–ª—å –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω –ø–æ—Å–ª–µ –∑–∞–∫–∞–∑–∞',
            'future_bid': '–ë–∏–¥ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –¥–æ —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–∫–∞–∑–∞',
            'slow_response': '–ú–µ–¥–ª–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –≤–æ–¥–∏—Ç–µ–ª—è (>5 –º–∏–Ω)',
            'zero_distance': '–ù—É–ª–µ–≤–æ–µ/–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ',
            'zero_duration': '–ù—É–ª–µ–≤–∞—è/–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å',
            'zero_price': '–ù—É–ª–µ–≤–∞—è/–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è —Ü–µ–Ω–∞',
            'extreme_distance': '–°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è –ø–æ–µ–∑–¥–∫–∞ (>100 –∫–º)',
            'extreme_duration': '–°–ª–∏—à–∫–æ–º –¥–æ–ª–≥–∞—è –ø–æ–µ–∑–¥–∫–∞ (>2 —á)',
            'too_fast_city': '–°–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å (>80 –∫–º/—á)',
            'physically_impossible': '–§–∏–∑–∏—á–µ—Å–∫–∏ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å (>120 –∫–º/—á)',
            'too_slow': '–°–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å (<8 –∫–º/—á)',
            'extreme_pickup_ratio': '–ü–æ–¥–∞—á–∞ >5x –¥–ª–∏–Ω–Ω–µ–µ –ø–æ–µ–∑–¥–∫–∏',
            'extreme_pickup_speed': '–°–∫–æ—Ä–æ—Å—Ç—å –ø–æ–¥–∞—á–∏ >100 –∫–º/—á',
            'extreme_markup': '–ù–∞—Ü–µ–Ω–∫–∞ >100%',
            'extreme_price': '–¶–µ–Ω–∞ >5000‚ÇΩ'
        }
        
        print(f"{'–ü—Ä–æ–±–ª–µ–º–∞':<50s} {'–ó–∞–ø–∏—Å–µ–π':>10s}")
        print("-"*62)
        
        for name, mask in problems.items():
            count = mask.sum()
            if count > 0:
                desc = descriptions.get(name, name)
                print(f"{desc:<50s} {count:>10d}")
    
    # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–∞—Å–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è
    delete_mask = pd.Series(False, index=df.index)
    for mask in problems.values():
        delete_mask |= mask
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä
    df_clean = df[~delete_mask].copy()
    
    if verbose:
        print("-"*62)
        print(f"{'–ò–¢–û–ì–û —É–¥–∞–ª–µ–Ω–æ:':<50s} {delete_mask.sum():>10d} ({delete_mask.sum()/initial_count*100:.1f}%)")
        print(f"{'–û—Å—Ç–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–µ–π:':<50s} {len(df_clean):>10d} ({len(df_clean)/initial_count*100:.1f}%)")
        
        # –ë–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤
        df_clean['is_done_binary'] = (df_clean['is_done'] == 'done').astype(int)
        done_count = df_clean['is_done_binary'].sum()
        cancel_count = len(df_clean) - done_count
        done_pct = done_count / len(df_clean) * 100
        
        print(f"\n{'–ë–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤:':<50s}")
        print(f"{'  Done':<50s} {done_count:>10d} ({done_pct:5.1f}%)")
        print(f"{'  Cancel':<50s} {cancel_count:>10d} ({100-done_pct:5.1f}%)")
        
        ratio = cancel_count / done_count
        print(f"\n{'scale_pos_weight –¥–ª—è XGBoost:':<50s} {ratio:>10.2f}")
        print("="*70)
    
    return df_clean


def detect_taxi_type(carname, carmodel):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —Ç–∞–∫—Å–∏ –ø–æ –º–∞—Ä–∫–µ –∏ –º–æ–¥–µ–ª–∏"""
    carname = str(carname).strip()
    carmodel = str(carmodel).strip()
    
    economy_brands = ['Daewoo', 'Lifan', 'FAW', 'Great Wall', 'Geely', '–ó–ê–ó', 'Chery']
    economy_models = [
        'Logan', 'Symbol', 'Sandero', 'Lacetti', 'Aveo', 'Nexia', 'Rio', 'Spectra',
        'Granta', '–ì—Ä–∞–Ω—Ç–∞', 'Kalina', '–ö–∞–ª–∏–Ω–∞', 'Priora', '–ü—Ä–∏–æ—Ä–∞', 
        '2110', '2112', '2115', '2107', '2114', '–°–∞–º–∞—Ä–∞', 'S18'
    ]
    
    business_brands = ['Toyota', 'Honda', 'Mitsubishi', 'Subaru']
    business_models = [
        'Camry', 'Corolla', 'RAV4', 'Avensis', 'Civic', 'Accord', 
        'Qashqai', 'X-Trail', 'Tiguan', 'Passat CC', 'Passat',
        'CX-5', 'Outlander', 'Kyron', 'Legacy'
    ]
    
    lada_comfort_models = ['Vesta', '–í–µ—Å—Ç–∞', 'X-Ray', 'Largus', '–õ–∞—Ä–≥—É—Å', 'GFK110']
    
    if carname in economy_brands or carmodel in economy_models:
        return "economy"
    
    if carname in business_brands or carmodel in business_models:
        return "business"
    
    if carname in ['LADA', '–õ–∞–¥–∞', '–í–ê–ó (LADA)'] and carmodel in lada_comfort_models:
        return "comfort"
    
    return "comfort"


def build_enhanced_features(frame):
    """
    –°—Ç—Ä–æ–∏—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ —Ü–µ–Ω–æ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã
    –í–∫–ª—é—á–∞–µ—Ç price_bid_local –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏!
    """
    
    ts = pd.to_datetime(frame["order_timestamp"], errors="coerce")
    hour = ts.dt.hour.fillna(0)
    wday = ts.dt.weekday.fillna(0)
    
    features = {}
    
    # ========================================================================
    # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –¶–ï–ù–û–í–´–ï –ü–†–ò–ó–ù–ê–ö–ò
    # ========================================================================
    features['price_bid_local'] = frame['price_bid_local'].values
    features['price_start_local'] = frame['price_start_local'].values
    features['price_increase_abs'] = (frame['price_bid_local'] - frame['price_start_local']).values
    features['price_increase_pct'] = ((frame['price_bid_local'] - frame['price_start_local']) / 
                                      frame['price_start_local'] * 100).values
    features['is_price_increased'] = (features['price_increase_pct'] > 0).astype(float)
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ü–µ–Ω—ã (—Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ 0)
    features['price_per_km'] = frame['price_bid_local'] / (frame['distance_in_meters'] / 1000 + 0.1)
    features['price_per_minute'] = frame['price_bid_local'] / (frame['duration_in_seconds'] / 60 + 0.1)
    
    # ========================================================================
    # –í–†–ï–ú–ï–ù–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò
    # ========================================================================
    features['hour_sin'] = np.sin(2 * np.pi * hour / 24)
    features['hour_cos'] = np.cos(2 * np.pi * hour / 24)
    features['day_of_week'] = wday.values
    features['day_sin'] = np.sin(2 * np.pi * wday / 7)
    features['day_cos'] = np.cos(2 * np.pi * wday / 7)
    features['is_weekend'] = (wday >= 5).astype(float).values
    
    # –ß–∞—Å—ã –ø–∏–∫
    is_morning_rush = ((hour >= 7) & (hour <= 9)).astype(int)
    is_evening_rush = ((hour >= 17) & (hour <= 20)).astype(int)
    features['is_morning_peak'] = is_morning_rush.values
    features['is_evening_peak'] = is_evening_rush.values
    features['is_peak_hour'] = ((is_morning_rush + is_evening_rush) > 0).astype(float).values
    features['is_night'] = ((hour < 6) | (hour >= 22)).astype(float).values
    features['is_lunch_time'] = ((hour >= 12) & (hour <= 14)).astype(float).values
    
    # ========================================================================
    # –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò –ü–û–ï–ó–î–ö–ò
    # ========================================================================
    features['distance_in_meters'] = frame['distance_in_meters'].values
    features['duration_in_seconds'] = frame['duration_in_seconds'].values
    features['distance_km'] = (frame['distance_in_meters'] / 1000).values
    features['duration_min'] = (frame['duration_in_seconds'] / 60).values
    
    # –°–∫–æ—Ä–æ—Å—Ç—å (—Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ 0)
    speed = frame['distance_in_meters'] / (frame['duration_in_seconds'] + 0.1) * 3.6
    features['avg_speed_kmh'] = np.clip(speed.values, 0, 150)  # –ö–ª–∏–ø–Ω–µ–º –≤ —Ä–∞–∑—É–º–Ω—ã–µ –ø—Ä–µ–¥–µ–ª—ã
    features['is_traffic_jam'] = (features['avg_speed_kmh'] < 15).astype(float)
    features['is_highway'] = (features['avg_speed_kmh'] > 50).astype(float)
    
    # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–∏—Å—Ç–∞–Ω—Ü–∏–∏
    dist = features['distance_km']
    features['is_short_trip'] = (dist < 2).astype(float)
    features['is_medium_trip'] = ((dist >= 2) & (dist < 10)).astype(float)
    features['is_long_trip'] = (dist >= 10).astype(float)
    
    # ========================================================================
    # –ü–û–î–ê–ß–ê –í–û–î–ò–¢–ï–õ–Ø
    # ========================================================================
    features['pickup_in_meters'] = frame['pickup_in_meters'].values
    features['pickup_in_seconds'] = frame['pickup_in_seconds'].values
    features['pickup_km'] = (frame['pickup_in_meters'] / 1000).values
    
    pickup_speed = frame['pickup_in_meters'] / (frame['pickup_in_seconds'] + 0.1) * 3.6
    features['pickup_speed_kmh'] = np.clip(pickup_speed.values, 0, 150)
    
    # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è (—Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ 0)
    features['pickup_to_trip_ratio'] = np.clip(
        frame['pickup_in_meters'] / (frame['distance_in_meters'] + 1).values,
        0, 10  # –ú–∞–∫—Å–∏–º—É–º 10x
    )
    features['pickup_time_ratio'] = np.clip(
        frame['pickup_in_seconds'] / (frame['duration_in_seconds'] + 1).values,
        0, 10
    )
    features['total_distance'] = (frame['pickup_in_meters'] + frame['distance_in_meters']).values
    features['total_time'] = (frame['pickup_in_seconds'] + frame['duration_in_seconds']).values
    
    # ========================================================================
    # –í–û–î–ò–¢–ï–õ–¨
    # ========================================================================
    features['driver_rating'] = frame['driver_rating'].values
    
    # –°—Ç–∞–∂ –≤–æ–¥–∏—Ç–µ–ª—è
    driver_reg = pd.to_datetime(frame['driver_reg_date'], errors='coerce')
    experience_days = (ts - driver_reg).dt.days.fillna(365)
    experience_days = np.clip(experience_days.values, 0, 3650)  # –ú–∞–∫—Å 10 –ª–µ—Ç
    features['driver_experience_days'] = experience_days
    features['driver_experience_years'] = experience_days / 365.25
    features['is_new_driver'] = (experience_days < 30).astype(float)
    features['is_experienced_driver'] = (experience_days > 365).astype(float)
    features['has_perfect_rating'] = (frame['driver_rating'] == 5.0).astype(float).values
    features['rating_deviation'] = (5.0 - frame['driver_rating']).values
    
    # –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞
    tender_ts = pd.to_datetime(frame['tender_timestamp'], errors='coerce')
    response_time = (tender_ts - ts).dt.total_seconds().fillna(30)
    response_time = np.clip(response_time.values, 0, 600)  # –ú–∞–∫—Å 10 –º–∏–Ω—É—Ç
    features['response_time_seconds'] = response_time
    features['response_time_log'] = np.log1p(response_time)
    features['is_fast_response'] = (response_time < 10).astype(float)
    features['is_slow_response'] = (response_time > 60).astype(float)
    
    # ========================================================================
    # –ê–í–¢–û–ú–û–ë–ò–õ–¨
    # ========================================================================
    taxi_types = frame.apply(lambda row: detect_taxi_type(row['carname'], row['carmodel']), axis=1)
    features['taxi_type_economy'] = (taxi_types == 'economy').astype(float).values
    features['taxi_type_comfort'] = (taxi_types == 'comfort').astype(float).values
    features['taxi_type_business'] = (taxi_types == 'business').astype(float).values
    
    # –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞
    features['platform_android'] = (frame['platform'] == 'android').astype(float).values
    features['platform_ios'] = (frame['platform'] == 'ios').astype(float).values
    
    # ========================================================================
    # –í–ó–ê–ò–ú–û–î–ï–ô–°–¢–í–ò–Ø –ü–†–ò–ó–ù–ê–ö–û–í
    # ========================================================================
    features['price_inc_x_distance'] = features['price_increase_pct'] * features['distance_km']
    features['price_inc_x_night'] = features['price_increase_pct'] * features['is_night']
    features['price_inc_x_peak'] = features['price_increase_pct'] * features['is_peak_hour']
    features['price_inc_x_weekend'] = features['price_increase_pct'] * features['is_weekend']
    
    features['distance_x_night'] = features['distance_km'] * features['is_night']
    features['distance_x_weekend'] = features['distance_km'] * features['is_weekend']
    features['distance_x_peak'] = features['distance_km'] * features['is_peak_hour']
    
    features['speed_x_peak'] = features['avg_speed_kmh'] * features['is_peak_hour']
    features['rating_x_price_inc'] = features['driver_rating'] * features['price_increase_pct']
    features['experience_x_price_inc'] = features['driver_experience_years'] * features['price_increase_pct']
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame
    result = pd.DataFrame(features)
    
    # ========================================================================
    # –£–°–ò–õ–ï–ù–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê NaN –∏ Inf
    # ========================================================================
    
    # 1. –ó–∞–º–µ–Ω—è–µ–º Inf –Ω–∞ NaN
    result = result.replace([np.inf, -np.inf], np.nan)
    
    # 2. –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –º–µ–¥–∏–∞–Ω–æ–π –ò–õ–ò –Ω—É–ª—ë–º –µ—Å–ª–∏ –º–µ–¥–∏–∞–Ω–∞ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞
    for col in result.columns:
        if result[col].isna().any():
            median_val = result[col].median()
            if pd.isna(median_val) or np.isinf(median_val):
                result[col] = result[col].fillna(0)
            else:
                result[col] = result[col].fillna(median_val)
    
    # 3. –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ –æ—á–∏—Å—Ç–∫–∞
    result = result.fillna(0)  # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
    result = result.replace([np.inf], 1e10)
    result = result.replace([-np.inf], -1e10)
    
    # 4. –ö–ª–∏–ø–Ω–µ–º –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Ä–∞–∑—É–º–Ω—ã–µ –ø—Ä–µ–¥–µ–ª—ã
    for col in result.columns:
        if result[col].std() > 0:  # –¢–æ–ª—å–∫–æ –¥–ª—è –∏–∑–º–µ–Ω—è—é—â–∏—Ö—Å—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            mean = result[col].mean()
            std = result[col].std()
            result[col] = np.clip(result[col], mean - 10*std, mean + 10*std)
    
    return result


def train_model(train_path="simple-train.csv", use_gpu=False, test_size=0.2, random_state=42):
    """
    –û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å XGBoost —Å –∫–∞–ª–∏–±—Ä–æ–≤–∫–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
    """
    
    print("\n" + "="*70)
    print("–û–ë–£–ß–ï–ù–ò–ï ML-–ú–û–î–ï–õ–ò DRIVEE")
    print("="*70)
    
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print(f"\nüìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {train_path}...")
    df = pd.read_csv(train_path)
    print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(df)} –∑–∞–ø–∏—Å–µ–π")
    
    # 2. –ö–†–ò–¢–ò–ß–ù–û: –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df = clean_and_validate_data(df, verbose=True)
    
    if len(df) < 100:
        raise ValueError("‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏—Å—Ö–æ–¥–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç.")
    
    # 3. –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
    print("\nüéØ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π...")
    y = (df['is_done'] == 'done').astype(int)
    print(f"   Done: {y.sum()} ({y.mean()*100:.1f}%)")
    print(f"   Cancel: {(~y.astype(bool)).sum()} ({(1-y.mean())*100:.1f}%)")
    
    # 4. Feature Engineering
    print("\nüîß –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    X = build_enhanced_features(df)
    print(f"   –°–æ–∑–¥–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X.shape[1]}")
    print(f"   –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {X.shape[0]} –∑–∞–ø–∏—Å–µ–π √ó {X.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    
    # 5. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
    print(f"\nüìä –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö (test_size={test_size})...")
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=y
    )
    print(f"   Train: {len(X_train)} –∑–∞–ø–∏—Å–µ–π")
    print(f"   Test:  {len(X_test)} –∑–∞–ø–∏—Å–µ–π")
    
    # 6. –û–±—É—á–µ–Ω–∏–µ XGBoost
    print("\nü§ñ –û–±—É—á–µ–Ω–∏–µ XGBoost...")
    
    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()
    
    params = {
        'n_estimators': 300,
        'learning_rate': 0.05,
        'max_depth': 8,
        'min_child_weight': 5,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'gamma': 0.1,
        'reg_alpha': 0.1,
        'reg_lambda': 1.0,
        'scale_pos_weight': scale_pos_weight,
        'tree_method': 'gpu_hist' if use_gpu else 'hist',
        'random_state': random_state,
        'eval_metric': 'logloss'
    }
    
    print(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:")
    print(f"     ‚Ä¢ n_estimators: {params['n_estimators']}")
    print(f"     ‚Ä¢ learning_rate: {params['learning_rate']}")
    print(f"     ‚Ä¢ max_depth: {params['max_depth']}")
    print(f"     ‚Ä¢ scale_pos_weight: {scale_pos_weight:.2f}")
    print(f"     ‚Ä¢ tree_method: {params['tree_method']}")
    
    model = xgb.XGBClassifier(**params)
    
    model.fit(
        X_train, y_train,
        eval_set=[(X_test, y_test)],
        verbose=False
    )
    
    # 7. –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
    print("\nüé≤ –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π...")
    calibrated_model = CalibratedClassifierCV(
        model, 
        method='sigmoid',
        cv='prefit'
    )
    calibrated_model.fit(X_train, y_train)
    
    # 8. –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
    print("\nüìà –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏:")
    
    y_train_pred = calibrated_model.predict_proba(X_train)[:, 1]
    train_auc = roc_auc_score(y_train, y_train_pred)
    
    y_test_pred = calibrated_model.predict_proba(X_test)[:, 1]
    test_auc = roc_auc_score(y_test, y_test_pred)
    
    precision, recall, _ = precision_recall_curve(y_test, y_test_pred)
    pr_auc = auc(recall, precision)
    
    print(f"   ROC-AUC (train): {train_auc:.4f}")
    print(f"   ROC-AUC (test):  {test_auc:.4f}")
    print(f"   PR-AUC (test):   {pr_auc:.4f}")
    
    # Feature importance
    print("\nüîù –¢–æ–ø-10 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    for idx, row in feature_importance.head(10).iterrows():
        print(f"   {row['feature']:30s} {row['importance']:.4f}")
    
    # 9. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    joblib.dump(calibrated_model, "model_enhanced.joblib")
    print("   ‚úì –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: model_enhanced.joblib")
    
    joblib.dump(X.columns.tolist(), "feature_names.joblib")
    print("   ‚úì –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: feature_names.joblib")
    
    print("\n" + "="*70)
    print("‚úÖ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–ï–®–ù–û!")
    print("="*70)
    
    return calibrated_model, feature_importance


if __name__ == "__main__":
    try:
        model, importance = train_model(
            train_path="simple-train.csv",
            use_gpu=False,
            test_size=0.2,
            random_state=42
        )
        print("\nüéâ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏: {e}")
        import traceback
        traceback.print_exc()
